<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 17]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.CL](#cs.CL) [Total: 11]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.LG](#cs.LG) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement](https://arxiv.org/abs/2506.19939)
*Aryan Singh Dalal,Sidharth Rai,Rahul Singh,Treman Singh Kaloya,Rahul Harsha Cheppally,Ajay Sharda*

Main category: cs.CV

TL;DR: 开发了一种基于计算机视觉的系统，用于量化农业喷雾器喷杆的运动，以提高喷雾应用的准确性。


<details>
  <summary>Details</summary>
Motivation: 喷雾杆的不稳定性是农业喷雾器应用中误差的主要来源之一，但目前缺乏定量数据来改进设计和控制系统。

Method: 使用YOLO V7、V8和V11神经网络模型实时跟踪喷杆上的目标，并结合倾角传感器验证模型输出。

Result: 模型检测目标的准确率超过90%，距离估计与传感器数据误差在0.026米以内。

Conclusion: 该系统能有效量化喷杆运动，为改进喷雾器设计和提高应用精度提供数据支持。

Abstract: Application rate errors when using self-propelled agricultural sprayers for
agricultural production remain a concern. Among other factors, spray boom
instability is one of the major contributors to application errors. Spray
booms' width of 38m, combined with 30 kph driving speeds, varying terrain, and
machine dynamics when maneuvering complex field boundaries, make controls of
these booms very complex. However, there is no quantitative knowledge on the
extent of boom movement to systematically develop a solution that might include
boom designs and responsive boom control systems. Therefore, this study was
conducted to develop an automated computer vision system to quantify the boom
movement of various agricultural sprayers. A computer vision system was
developed to track a target on the edge of the sprayer boom in real time. YOLO
V7, V8, and V11 neural network models were trained to track the boom's
movements in field operations to quantify effective displacement in the
vertical and transverse directions. An inclinometer sensor was mounted on the
boom to capture boom angles and validate the neural network model output. The
results showed that the model could detect the target with more than 90 percent
accuracy, and distance estimates of the target on the boom were within 0.026 m
of the inclinometer sensor data. This system can quantify the boom movement on
the current sprayer and potentially on any other sprayer with minor
modifications. The data can be used to make design improvements to make sprayer
booms more stable and achieve greater application accuracy.

</details>


### [2] [EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression](https://arxiv.org/abs/2506.19955)
*Yiming Ma,Victor Sanchez,Tanaya Guha*

Main category: cs.CV

TL;DR: EBC-ZIP提出了一种基于零膨胀泊松回归的人群计数框架，解决了现有方法忽略密度图稀疏性及损失函数不适合离散计数数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略地面真实密度图的极端稀疏性，导致模型在稀疏区域表现不佳，且传统损失函数假设高斯分布，不适合离散计数数据。

Method: 提出EBC-ZIP框架，采用零膨胀泊松回归的负对数似然作为损失函数，结合增强块分类框架的优势。

Result: 在四个基准测试中，EBC-ZIP表现优于EBC，并达到最先进水平。

Conclusion: EBC-ZIP通过更合理的概率损失函数，显著提升了人群计数的性能。

Abstract: Density map estimation has become the mainstream paradigm in crowd counting.
However, most existing methods overlook the extreme sparsity of ground-truth
density maps. In real-world crowd scenes, the vast majority of spatial regions
(often over 95%) contain no people, leading to heavily imbalanced count
distributions. Ignoring this imbalance can bias models toward overestimating
dense regions and underperforming in sparse areas. Furthermore, most loss
functions used in density estimation are majorly based on MSE and implicitly
assume Gaussian distributions, which are ill-suited for modeling discrete,
non-negative count data. In this paper, we propose EBC-ZIP, a crowd counting
framework that models the spatial distribution of counts using a Zero-Inflated
Poisson (ZIP) regression formulation. Our approach replaces the traditional
regression loss with the negative log-likelihood of the ZIP distribution,
enabling better handling of zero-heavy distributions while preserving count
accuracy. Built upon the recently proposed Enhanced Block Classification (EBC)
framework, EBC-ZIP inherits EBC's advantages in preserving the discreteness of
targets and ensuring training stability, while further improving performance
through a more principled probabilistic loss. We also evaluate EBC-ZIP with
backbones of varying computational complexity to assess its scalability.
Extensive experiments on four crowd counting benchmarks demonstrate that
EBC-ZIP consistently outperforms EBC and achieves state-of-the-art results.

</details>


### [3] [ToSA: Token Merging with Spatial Awareness](https://arxiv.org/abs/2506.20066)
*Hsiang-Wei Huang,Wenhao Chai,Kuang-Ming Chen,Cheng-Yen Yang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: ToSA是一种新的令牌合并方法，结合语义和空间信息，通过深度图像生成伪空间令牌，优化ViT的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖视觉令牌的特征相似性进行合并，忽略了早期层中空间信息的重要性。

Method: 利用深度图像生成伪空间令牌，结合语义和空间信息指导令牌合并。

Result: 在多个基准测试中优于现有方法，显著减少ViT运行时间。

Conclusion: ToSA是一种高效的ViT加速解决方案，能更好地保留场景结构。

Abstract: Token merging has emerged as an effective strategy to accelerate Vision
Transformers (ViT) by reducing computational costs. However, existing methods
primarily rely on the visual token's feature similarity for token merging,
overlooking the potential of integrating spatial information, which can serve
as a reliable criterion for token merging in the early layers of ViT, where the
visual tokens only possess weak visual information. In this paper, we propose
ToSA, a novel token merging method that combines both semantic and spatial
awareness to guide the token merging process. ToSA leverages the depth image as
input to generate pseudo spatial tokens, which serve as auxiliary spatial
information for the visual token merging process. With the introduced spatial
awareness, ToSA achieves a more informed merging strategy that better preserves
critical scene structure. Experimental results demonstrate that ToSA
outperforms previous token merging methods across multiple benchmarks on visual
and embodied question answering while largely reducing the runtime of the ViT,
making it an efficient solution for ViT acceleration. The code will be
available at: https://github.com/hsiangwei0903/ToSA

</details>


### [4] [BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos](https://arxiv.org/abs/2506.20103)
*Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文介绍了BrokenVideos数据集，用于定位AI生成视频中的视觉伪影，提升检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: AI生成视频中存在视觉伪影，影响真实性和用户信任，但缺乏专门用于伪影定位的基准数据集。

Method: 提出BrokenVideos数据集，包含3,254个AI生成视频，带有像素级标注的伪影区域，并通过人工验证。

Result: 实验表明，使用BrokenVideos训练模型能显著提升伪影定位能力。

Conclusion: BrokenVideos为生成视频模型的伪影定位研究提供了重要基准。

Abstract: Recent advances in deep generative models have led to significant progress in
video generation, yet the fidelity of AI-generated videos remains limited.
Synthesized content often exhibits visual artifacts such as temporally
inconsistent motion, physically implausible trajectories, unnatural object
deformations, and local blurring that undermine realism and user trust.
Accurate detection and spatial localization of these artifacts are crucial for
both automated quality control and for guiding the development of improved
generative models. However, the research community currently lacks a
comprehensive benchmark specifically designed for artifact localization in AI
generated videos. Existing datasets either restrict themselves to video or
frame level detection or lack the fine-grained spatial annotations necessary
for evaluating localization methods. To address this gap, we introduce
BrokenVideos, a benchmark dataset of 3,254 AI-generated videos with
meticulously annotated, pixel-level masks highlighting regions of visual
corruption. Each annotation is validated through detailed human inspection to
ensure high quality ground truth. Our experiments show that training state of
the art artifact detection models and multi modal large language models (MLLMs)
on BrokenVideos significantly improves their ability to localize corrupted
regions. Through extensive evaluation, we demonstrate that BrokenVideos
establishes a critical foundation for benchmarking and advancing research on
artifact localization in generative video models. The dataset is available at:
https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.

</details>


### [5] [From 2D to 3D Cognition: A Brief Survey of General World Models](https://arxiv.org/abs/2506.20134)
*Ningwei Xie,Zizi Tian,Lei Yang,Xiao-Ping Zhang,Meng Guo,Jie Li*

Main category: cs.CV

TL;DR: 本文综述了从2D感知到3D认知的世界模型发展，提出了一个概念框架，并分析了3D表示和世界知识两大技术驱动力，以及3D世界建模的三大核心能力。


<details>
  <summary>Details</summary>
Motivation: 当前领域缺乏对3D认知世界模型新兴技术的系统分类和分析，本文旨在填补这一空白。

Method: 通过引入概念框架，系统回顾了从2D到3D的世界模型技术，重点分析了3D表示和世界知识的作用，并探讨了三大核心能力。

Result: 总结了3D世界模型在物理场景生成、空间推理和交互方面的能力，并讨论了其在具体应用中的部署。

Conclusion: 指出了数据、建模和部署中的挑战，并提出了未来研究方向，以推动更鲁棒和通用的3D世界模型发展。

Abstract: World models have garnered increasing attention in the development of
artificial general intelligence (AGI), serving as computational frameworks for
learning representations of the external world and forecasting future states.
While early efforts focused on 2D visual perception and simulation, recent
3D-aware generative world models have demonstrated the ability to synthesize
geometrically consistent, interactive 3D environments, marking a shift toward
3D spatial cognition. Despite rapid progress, the field lacks systematic
analysis to categorize emerging techniques and clarify their roles in advancing
3D cognitive world models. This survey addresses this need by introducing a
conceptual framework, providing a structured and forward-looking review of
world models transitioning from 2D perception to 3D cognition. Within this
framework, we highlight two key technological drivers, particularly advances in
3D representations and the incorporation of world knowledge, as fundamental
pillars. Building on these, we dissect three core cognitive capabilities that
underpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning,
and 3D spatial interaction. We further examine the deployment of these
capabilities in real-world applications, including embodied AI, autonomous
driving, digital twin, and gaming/VR. Finally, we identify challenges across
data, modeling, and deployment, and outline future directions for advancing
more robust and generalizable 3D world models.

</details>


### [6] [EAR: Erasing Concepts from Unified Autoregressive Models](https://arxiv.org/abs/2506.20151)
*Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为EAR的微调方法，用于在自回归模型中实现高效且保留效用的概念擦除，并引入了WGA和TLM策略以及ECGVF基准。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在视觉理解和图像生成任务中表现优异，但如何在保持生成质量的同时去除不期望的概念仍是一个挑战。

Method: 提出EAR方法，结合WGA策略和TLM策略，并引入ECGVF基准进行评估。

Result: 实验表明，EAR在概念擦除效果和模型效用保留方面均有显著提升。

Conclusion: EAR方法有效解决了自回归模型中的概念擦除问题，同时保持了模型性能。

Abstract: Autoregressive (AR) models have achieved unified and strong performance
across both visual understanding and image generation tasks. However, removing
undesired concepts from AR models while maintaining overall generation quality
remains an open challenge. In this paper, we propose Erasure Autoregressive
Model (EAR), a fine-tuning method for effective and utility-preserving concept
erasure in AR models. Specifically, we introduce Windowed Gradient Accumulation
(WGA) strategy to align patch-level decoding with erasure objectives, and
Thresholded Loss Masking (TLM) strategy to protect content unrelated to the
target concept during fine-tuning. Furthermore, we propose a novel benchmark,
Erase Concept Generator and Visual Filter (ECGVF), aim at provide a more
rigorous and comprehensive foundation for evaluating concept erasure in AR
models. Specifically, we first employ structured templates across diverse large
language models (LLMs) to pre-generate a large-scale corpus of
target-replacement concept prompt pairs. Subsequently, we generate images from
these prompts and subject them to rigorous filtering via a visual classifier to
ensure concept fidelity and alignment. Extensive experimental results conducted
on the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR
achieves marked improvements in both erasure effectiveness and model utility
preservation. Code is available at: https://github.com/immc-lab/ear/

</details>


### [7] [Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration](https://arxiv.org/abs/2506.20152)
*Deepak Ghimire,Kilho Lee,Seong-heum Kim*

Main category: cs.CV

TL;DR: 本文提出了一种高效的损失感知自动选择结构化剪枝标准（LAASP）方法，用于压缩和加速深度神经网络。该方法采用边训练边剪枝的策略，自动选择剪枝标准和层，并通过短暂重训练减少剪枝带来的精度损失。实验表明，该方法在CIFAR-10和ImageNet数据集上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统的剪枝方法需要分阶段进行（训练、剪枝、微调），效率较低。本文旨在通过边训练边剪枝的方式，简化流程并提高剪枝效果。

Method: 提出LAASP方法，自动选择剪枝标准和层，结合边训练边剪枝的策略，并通过短暂重训练减少精度损失。

Result: 在CIFAR-10数据集上，ResNet56和ResNet110模型的FLOPs减少52%，精度提升；在ImageNet数据集上，ResNet50模型的FLOPs减少42%，精度仅下降0.33%。

Conclusion: LAASP方法在压缩神经网络的同时保持了高精度，适用于资源受限的边缘设备。

Abstract: Structured pruning is a well-established technique for compressing neural
networks, making it suitable for deployment in resource-limited edge devices.
This paper presents an efficient Loss-Aware Automatic Selection of Structured
Pruning Criteria (LAASP) for slimming and accelerating deep neural networks.
The majority of pruning methodologies employ a sequential process consisting of
three stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed
pruning technique adopts a pruning-while-training approach that eliminates the
first stage and integrates the second and third stages into a single cycle. The
automatic selection of magnitude or similarity-based filter pruning criteria
from a specified pool of criteria and the specific pruning layer at each
pruning iteration is guided by the network's overall loss on a small subset of
the training data. To mitigate the abrupt accuracy drop due to pruning, the
network is retrained briefly after each reduction of a predefined number of
floating-point operations (FLOPs). The optimal pruning rates for each layer in
the network are automatically determined, eliminating the need for manual
allocation of fixed or variable pruning rates for each layer. Experiments on
the VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets
demonstrate the effectiveness of the proposed method. In particular, the
ResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the
top-1 accuracy compared to state-of-the-art methods while reducing the network
FLOPs by 52\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces
FLOPs by more than 42\% with a negligible 0.33\% drop in top-5 accuracy. The
source code of this paper is publicly available online -
https://github.com/ghimiredhikura/laasp.

</details>


### [8] [Towards Efficient Exemplar Based Image Editing with Multimodal VLMs](https://arxiv.org/abs/2506.20155)
*Avadhoot Jadhav,Ashutosh Srivastava,Abhinav Java,Silky Singh,Tarun Ram Menta,Surgan Jandial,Balaji Krishnamurthy*

Main category: cs.CV

TL;DR: 本文提出了一种基于示例对的图像编辑方法，利用预训练的文本到图像扩散模型和多模态视觉语言模型，无需优化即可实现高效的编辑效果。


<details>
  <summary>Details</summary>
Motivation: 由于仅通过文本描述难以捕捉所有类型的图像编辑需求，示例对（编辑前后的图像）能更直观地表达编辑意图。

Method: 利用预训练的文本到图像扩散模型和多模态视觉语言模型，构建端到端的优化自由流程。

Result: 实验表明，该方法在多种编辑类型上优于基线方法，且速度提升约4倍。

Conclusion: 该方法通过示例对实现了高效且高质量的图像编辑，展示了预训练模型在编辑任务中的潜力。

Abstract: Text-to-Image Diffusion models have enabled a wide array of image editing
applications. However, capturing all types of edits through text alone can be
challenging and cumbersome. The ambiguous nature of certain image edits is
better expressed through an exemplar pair, i.e., a pair of images depicting an
image before and after an edit respectively. In this work, we tackle
exemplar-based image editing -- the task of transferring an edit from an
exemplar pair to a content image(s), by leveraging pretrained text-to-image
diffusion models and multimodal VLMs. Even though our end-to-end pipeline is
optimization-free, our experiments demonstrate that it still outperforms
baselines on multiple types of edits while being ~4x faster.

</details>


### [9] [Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2506.20168)
*Zhentao He,Can Zhang,Ziheng Wu,Zhenghao Chen,Yufei Zhan,Yifan Li,Zhao Zhang,Xian Wang,Minghui Qiu*

Main category: cs.CV

TL;DR: 论文提出KIE-HVQA基准，评估OCR幻觉问题，并引入GRPO框架以减少幻觉，实验显示其7B模型在幻觉减少上优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉退化场景中表现不佳，易产生幻觉内容，需改进视觉-文本推理能力。

Method: 提出KIE-HVQA基准模拟真实退化文档，并设计GRPO框架，结合视觉不确定性和拒绝回答机制。

Result: 7B模型在KIE-HVQA上幻觉减少22%，且标准任务性能无显著下降。

Conclusion: GRPO框架有效减少幻觉，提升模型在退化场景中的鲁棒性。

Abstract: Recent advancements in multimodal large language models have enhanced
document understanding by integrating textual and visual information. However,
existing models exhibit incompleteness within their paradigm in real-world
scenarios, particularly under visual degradation. In such conditions, the
current response paradigm often fails to adequately perceive visual degradation
and ambiguity, leading to overreliance on linguistic priors or misaligned
visual-textual reasoning. This difficulty in recognizing uncertainty frequently
results in the generation of hallucinatory content, especially when a precise
answer is not feasible. To better demonstrate and analyze this phenomenon and
problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR
hallucination in degraded document understanding. This dataset includes test
samples spanning identity cards and invoices, with simulated real-world
degradations for OCR reliability. This setup allows for evaluating models'
capacity, under degraded input, to distinguish reliable visual information and
answer accordingly, thereby highlighting the challenge of avoiding
hallucination on uncertain data. To achieve vision-faithful reasoning and
thereby avoid the aforementioned issues, we further introduce a GRPO-based
framework featuring a novel reward mechanism. By incorporating a self-awareness
of visual uncertainty and an analysis method that initiates refusal to answer
to increase task difficulty within our supervised fine-tuning and reinforcement
learning framework, we successfully mitigated hallucinations in ambiguous
regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model
achieves a 22\% absolute improvement in hallucination-free accuracy over GPT-4o
on KIE-HVQA and there is no significant performance drop in standard tasks,
highlighting both effectiveness and robustness.

</details>


### [10] [Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition](https://arxiv.org/abs/2506.20174)
*Man Duc Chuc*

Main category: cs.CV

TL;DR: 研究探讨了如何通过结合预训练的遥感与通用视觉基础模型，提升地球观测任务的性能，发现特征级集成小模型可媲美或超越大模型，且更高效。


<details>
  <summary>Details</summary>
Motivation: 探索预训练模型的复用与组合，以替代从头训练大型模型的传统方法，提高地球观测数据挖掘的效率和性能。

Method: 利用GEO-Bench基准测试，评估包括Prithvi、Hiera和DOFA在内的多个模型在11个数据集上的表现，采用特征级集成方法。

Result: 特征级集成的小模型性能可媲美或超越大模型，且训练时间和计算资源需求更低；知识蒸馏可进一步压缩模型。

Conclusion: 预训练模型的组合与知识蒸馏为地球观测任务提供了高效且实用的解决方案。

Abstract: Foundation models are rapidly transforming Earth Observation data mining by
enabling generalizable and scalable solutions for key tasks such as scene
classification and semantic segmentation. While most efforts in the geospatial
domain have focused on developing large models trained from scratch using
massive Earth Observation datasets, an alternative strategy that remains
underexplored is the reuse and combination of existing pretrained models. In
this study, we investigate whether foundation models pretrained on remote
sensing and general vision datasets can be effectively combined to improve
performance across a diverse set of key Earth Observation tasks. Using the
GEO-Bench benchmark, we evaluate several prominent models, including Prithvi,
Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,
sensor modalities, and task types. The results show that feature-level
ensembling of smaller pretrained models can match or exceed the performance of
much larger models, while requiring less training time and computational
resources. Moreover, the study highlights the potential of applying knowledge
distillation to transfer the strengths of ensembles into more compact models,
offering a practical path for deploying foundation models in real-world Earth
Observation applications.

</details>


### [11] [Progressive Alignment Degradation Learning for Pansharpening](https://arxiv.org/abs/2506.20179)
*Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu*

Main category: cs.CV

TL;DR: 论文提出了一种新的深度学习方法（PADM和HFreqdiff），用于改进基于Wald协议的图像融合技术，解决了传统方法在真实世界退化模式上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统Wald协议生成的合成数据无法准确模拟真实世界的退化模式，限制了深度图像融合模型的泛化能力。

Method: 提出了渐进对齐退化模块（PADM）和HFreqdiff框架，通过自适应学习退化过程和高频细节扩散，提升图像融合质量。

Result: 实验表明，该方法在空间清晰度和图像质量上显著优于现有技术。

Conclusion: PADM和HFreqdiff有效解决了传统方法的局限性，为高分辨率图像融合提供了新思路。

Abstract: Deep learning-based pansharpening has been shown to effectively generate
high-resolution multispectral (HRMS) images. To create supervised ground-truth
HRMS images, synthetic data generated using the Wald protocol is commonly
employed. This protocol assumes that networks trained on artificial
low-resolution data will perform equally well on high-resolution data. However,
well-trained models typically exhibit a trade-off in performance between
reduced-resolution and full-resolution datasets. In this paper, we delve into
the Wald protocol and find that its inaccurate approximation of real-world
degradation patterns limits the generalization of deep pansharpening models. To
address this issue, we propose the Progressive Alignment Degradation Module
(PADM), which uses mutual iteration between two sub-networks, PAlignNet and
PDegradeNet, to adaptively learn accurate degradation processes without relying
on predefined operators. Building on this, we introduce HFreqdiff, which embeds
high-frequency details into a diffusion framework and incorporates CFB and BACM
modules for frequency-selective detail extraction and precise reverse process
learning. These innovations enable effective integration of high-resolution
panchromatic and multispectral images, significantly enhancing spatial
sharpness and quality. Experiments and ablation studies demonstrate the
proposed method's superior performance compared to state-of-the-art techniques.

</details>


### [12] [UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.20214)
*Yanzhe Chen,Huasong Zhong,Yan Li,Zhenheng Yang*

Main category: cs.CV

TL;DR: UniCode^2提出了一种级联码本框架，用于大规模、语义对齐且稳定的视觉标记化，解决了现有方法在词汇量小或训练不稳定上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于码本的方法要么词汇量小（约16K条目），缺乏细粒度语义，要么盲目扩展导致标记利用率低和训练不稳定。

Method: 通过聚类数百万SigLIP序列嵌入，构建了一个50万条目的码本，采用级联设计：冻结码本锚定嵌入空间，可训练码本细化任务特定语义。

Result: UniCode^2在多样化基准测试中表现优异，支持高质量视觉合成，且无需牺牲稳定性、语义或模块性。

Conclusion: UniCode^2证明了在不牺牲稳定性、语义或模块性的前提下扩展视觉标记空间的可行性。

Abstract: Unified multimodal large language models (MLLMs) have shown promise in
jointly advancing multimodal understanding and generation, with visual
codebooks discretizing images into tokens for autoregressive modeling. Existing
codebook-based methods either rely on small vocabularies (~16K entries) that
lack fine-grained semantics or naively scale up, resulting in low token
utilization and unstable training. We propose UniCode$^2$, a cascaded codebook
framework enabling large-scale, semantically aligned, and stable visual
tokenization. By clustering millions of SigLIP sequence embeddings, we build a
500K-entry codebook that preserves vision-language alignment while expanding
capacity. Stability is ensured via a cascaded design: a frozen codebook anchors
the embedding space, and a trainable codebook refines task-specific semantics.
This decoupling promotes high utilization and robust learning. Moreover, the
alignment of our visual tokens with textual semantics enables seamless
integration with pretrained diffusion decoders, supporting high-quality visual
synthesis with minimal adaptation. UniCode^2 delivers strong performance across
diverse benchmarks, demonstrating the viability of scaling visual token spaces
without sacrificing stability, semantics, or modularity.

</details>


### [13] [Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission](https://arxiv.org/abs/2506.20222)
*Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu*

Main category: cs.CV

TL;DR: 提出了一种联合事件和图像（E-I）传输框架，通过贝叶斯建模和信息瓶颈方法消除冗余，优化带宽利用，并实现实时去模糊。


<details>
  <summary>Details</summary>
Motivation: 混合系统中事件相机和RGB相机传输大量数据存在挑战，且两者输出存在冗余信息。

Method: 使用贝叶斯建模和信息瓶颈方法分离共享和领域特定信息，动态分配传输带宽。

Result: 仿真结果表明，该方案在重建质量和去模糊性能上优于传统系统。

Conclusion: 提出的框架有效优化了带宽利用，同时提升了重建和去模糊效果。

Abstract: Event cameras asynchronously capture pixel-level intensity changes with
extremely low latency. They are increasingly used in conjunction with RGB
cameras for a wide range of vision-related applications. However, a major
challenge in these hybrid systems lies in the transmission of the large volume
of triggered events and RGB images. To address this, we propose a transmission
scheme that retains efficient reconstruction performance of both sources while
accomplishing real-time deblurring in parallel. Conventional RGB cameras and
event cameras typically capture the same scene in different ways, often
resulting in significant redundant information across their outputs. To address
this, we develop a joint event and image (E-I) transmission framework to
eliminate redundancy and thereby optimize channel bandwidth utilization. Our
approach employs Bayesian modeling and the information bottleneck method to
disentangle the shared and domain-specific information within the E-I inputs.
This disentangled information bottleneck framework ensures both the compactness
and informativeness of extracted shared and domain-specific information.
Moreover, it adaptively allocates transmission bandwidth based on scene
dynamics, i.e., more symbols are allocated to events for dynamic details or to
images for static information. Simulation results demonstrate that the proposed
scheme not only achieves superior reconstruction quality compared to
conventional systems but also delivers enhanced deblurring performance.

</details>


### [14] [Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement](https://arxiv.org/abs/2506.20254)
*Kun Yuan,Tingxuan Chen,Shi Li,Joel L. Lavanchy,Christian Heiliger,Ege Özsoy,Yiming Huang,Long Bai,Nassir Navab,Vinkle Srivastav,Hongliang Ren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SPA是一个轻量级框架，通过少量标注和多模态适应，提升手术工作流理解的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术工作流的复杂性和多样性导致跨机构和跨手术的通用模型开发困难，现有基础模型在零样本性能上受限于领域偏移。

Method: SPA结合少量空间适应、扩散建模和动态测试时适应，通过自然语言定义阶段、少量标注和任务图快速定制模型。

Result: SPA在少量标注下实现了跨机构和手术的最先进性能，甚至优于全标注模型。

Conclusion: SPA为医院提供了一种高效、轻量级的方法，快速适应手术阶段识别模型。

Abstract: The complexity and diversity of surgical workflows, driven by heterogeneous
operating room settings, institutional protocols, and anatomical variability,
present a significant challenge in developing generalizable models for
cross-institutional and cross-procedural surgical understanding. While recent
surgical foundation models pretrained on large-scale vision-language data offer
promising transferability, their zero-shot performance remains constrained by
domain shifts, limiting their utility in unseen surgical environments. To
address this, we introduce Surgical Phase Anywhere (SPA), a lightweight
framework for versatile surgical workflow understanding that adapts foundation
models to institutional settings with minimal annotation. SPA leverages
few-shot spatial adaptation to align multi-modal embeddings with
institution-specific surgical scenes and phases. It also ensures temporal
consistency through diffusion modeling, which encodes task-graph priors derived
from institutional procedure protocols. Finally, SPA employs dynamic test-time
adaptation, exploiting the mutual agreement between multi-modal phase
prediction streams to adapt the model to a given test video in a
self-supervised manner, enhancing the reliability under test-time distribution
shifts. SPA is a lightweight adaptation framework, allowing hospitals to
rapidly customize phase recognition models by defining phases in natural
language text, annotating a few images with the phase labels, and providing a
task graph defining phase transitions. The experimental results show that the
SPA framework achieves state-of-the-art performance in few-shot surgical phase
recognition across multiple institutions and procedures, even outperforming
full-shot models with 32-shot labeled data. Code is available at
https://github.com/CAMMA-public/SPA

</details>


### [15] [A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features](https://arxiv.org/abs/2506.20255)
*Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal*

Main category: cs.CV

TL;DR: 论文提出一种结合离线图像和在线笔画数据的端到端网络，通过早期融合提升手写识别性能，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手写识别通常仅利用单一模态（如离线图像或在线笔画数据），而论文认为结合两种模态的互补线索能提升性能。

Method: 设计了一个端到端网络，在共享潜在空间中早期融合离线图像和在线笔画数据，使用补丁编码器和轻量级Transformer处理数据，并通过可学习的潜在查询增强上下文。

Result: 在IAMOn-DB和VNOn-DB数据集上实现了最先进的准确率，比之前最佳方法提升1%。

Conclusion: 早期融合多模态数据能增强表示学习，提升手写识别的性能和鲁棒性。

Abstract: We posit that handwriting recognition benefits from complementary cues
carried by the rasterized complex glyph and the pen's trajectory, yet most
systems exploit only one modality. We introduce an end-to-end network that
performs early fusion of offline images and online stroke data within a shared
latent space. A patch encoder converts the grayscale crop into fixed-length
visual tokens, while a lightweight transformer embeds the $(x, y, \text{pen})$
sequence. Learnable latent queries attend jointly to both token streams,
yielding context-enhanced stroke embeddings that are pooled and decoded under a
cross-entropy loss objective. Because integration occurs before any high-level
classification, temporal cues reinforce each other during representation
learning, producing stronger writer independence. Comprehensive experiments on
IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art
accuracy, exceeding previous bests by up to 1\%. Our study also shows
adaptation of this pipeline with gesturification on the ISI-Air dataset. Our
code can be found here.

</details>


### [16] [Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification](https://arxiv.org/abs/2506.20263)
*Ning Luo,Meiyin Hu,Huan Wan,Yanyan Yang,Zhuohang Jiang,Xin Wei*

Main category: cs.CV

TL;DR: 提出了一种名为HMDRN的新方法，通过双层次特征重建和掩码增强处理，显著提升了小样本细粒度图像分类的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度图像分类中存在空间信息丢失、局部特征错位、缺乏层次特征利用和判别区域关注机制等问题。

Method: HMDRN结合双层次特征重建与掩码增强处理，利用互补的视觉信息，并通过自适应阈值处理增强判别区域。

Result: 在三个细粒度数据集上，HMDRN表现优于现有方法，并通过消融实验验证了各模块的有效性。

Conclusion: HMDRN通过双层次重建和掩码增强，显著提升了分类性能，减少了类内差异。

Abstract: Few-shot fine-grained image classification (FS-FGIC) presents a significant
challenge, requiring models to distinguish visually similar subclasses with
limited labeled examples. Existing methods have critical limitations:
metric-based methods lose spatial information and misalign local features,
while reconstruction-based methods fail to utilize hierarchical feature
information and lack mechanisms to focus on discriminative regions. We propose
the Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which
integrates dual-layer feature reconstruction with mask-enhanced feature
processing to improve fine-grained classification. HMDRN incorporates a
dual-layer feature reconstruction and fusion module that leverages
complementary visual information from different network hierarchies. Through
learnable fusion weights, the model balances high-level semantic
representations from the last layer with mid-level structural details from the
penultimate layer. Additionally, we design a spatial binary mask-enhanced
transformer self-reconstruction module that processes query features through
adaptive thresholding while maintaining complete support features, enhancing
focus on discriminative regions while filtering background noise. Extensive
experiments on three challenging fine-grained datasets demonstrate that HMDRN
consistently outperforms state-of-the-art methods across Conv-4 and ResNet-12
backbone architectures. Comprehensive ablation studies validate the
effectiveness of each proposed component, revealing that dual-layer
reconstruction enhances inter-class discrimination while mask-enhanced
transformation reduces intra-class variations. Visualization results provide
evidence of HMDRN's superior feature reconstruction capabilities.

</details>


### [17] [Forensic Study of Paintings Through the Comparison of Fabrics](https://arxiv.org/abs/2506.20272)
*Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的纺织品相似性评估新方法，用于艺术品的鉴定与保护。


<details>
  <summary>Details</summary>
Motivation: 传统基于线密度图匹配的方法无法适用于非连续位置的画布，需要一种更通用的方法。

Method: 设计了Siamese深度学习模型，通过图像对比较学习特征表示，并提出相似性估计方法。

Result: 在Museo Nacional del Prado的画布上验证了方法的可行性，即使线密度相似也能有效比较。

Conclusion: 该方法为艺术品分析开辟了新途径，具有高准确性和实用性。

Abstract: The study of canvas fabrics in works of art is a crucial tool for
authentication, attribution and conservation. Traditional methods are based on
thread density map matching, which cannot be applied when canvases do not come
from contiguous positions on a roll. This paper presents a novel approach based
on deep learning to assess the similarity of textiles. We introduce an
automatic tool that evaluates the similarity between canvases without relying
on thread density maps. A Siamese deep learning model is designed and trained
to compare pairs of images by exploiting the feature representations learned
from the scans. In addition, a similarity estimation method is proposed,
aggregating predictions from multiple pairs of cloth samples to provide a
robust similarity score. Our approach is applied to canvases from the Museo
Nacional del Prado, corroborating the hypothesis that plain weave canvases,
widely used in painting, can be effectively compared even when their thread
densities are similar. The results demonstrate the feasibility and accuracy of
the proposed method, opening new avenues for the analysis of masterpieces.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [18] [RaRa Clipper: A Clipper for Gaussian Splatting Based on Ray Tracer and Rasterizer](https://arxiv.org/abs/2506.20202)
*Da Li,Donggang Jia,Yousef Rajeh,Dominik Engel,Ivan Viola*

Main category: cs.GR

TL;DR: 提出了一种结合光栅化和光线追踪的混合渲染框架（RaRa策略），用于高效且高保真地实现高斯泼溅数据的裁剪。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅数据的精确和高效裁剪是一个未解决的挑战，主要原因是高斯基元的体积特性使得硬裁剪难以精确定位其像素级贡献。

Method: 采用RaRa策略，先通过光栅化快速识别被裁剪平面相交的高斯基元，再通过光线追踪计算基于部分遮挡的衰减权重，以准确估计每个高斯基元对最终图像的贡献。

Result: 在多种数据集（包括普通高斯、发丝高斯和多层高斯）上验证了方法的有效性，用户研究表明其具有优越的感知质量和定量性能。

Conclusion: 该方法在保持实时渲染性能和高保真度的同时，实现了视觉上更优的裁剪效果。

Abstract: With the advancement of Gaussian Splatting techniques, a growing number of
datasets based on this representation have been developed. However, performing
accurate and efficient clipping for Gaussian Splatting remains a challenging
and unresolved problem, primarily due to the volumetric nature of Gaussian
primitives, which makes hard clipping incapable of precisely localizing their
pixel-level contributions. In this paper, we propose a hybrid rendering
framework that combines rasterization and ray tracing to achieve efficient and
high-fidelity clipping of Gaussian Splatting data. At the core of our method is
the RaRa strategy, which first leverages rasterization to quickly identify
Gaussians intersected by the clipping plane, followed by ray tracing to compute
attenuation weights based on their partial occlusion. These weights are then
used to accurately estimate each Gaussian's contribution to the final image,
enabling smooth and continuous clipping effects. We validate our approach on
diverse datasets, including general Gaussians, hair strand Gaussians, and
multi-layer Gaussians, and conduct user studies to evaluate both perceptual
quality and quantitative performance. Experimental results demonstrate that our
method delivers visually superior results while maintaining real-time rendering
performance and preserving high fidelity in the unclipped regions.

</details>


### [19] [X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis](https://arxiv.org/abs/2506.20267)
*Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger*

Main category: cs.GR

TL;DR: 论文提出了一种可解释的表面视觉变换器（X-SiT），用于基于可解释的皮层特征进行医学图像分析，并在阿尔茨海默病和额颞叶痴呆检测中表现出色。


<details>
  <summary>Details</summary>
Motivation: 3D体积数据的复杂性和难以可视化特性促使研究者开发更易理解的皮层表面渲染方法，以支持临床决策。

Method: 提出X-SiT，一种基于原型表面块解码器的神经网络，结合案例推理和空间对应的皮层原型进行分类。

Result: X-SiT在阿尔茨海默病和额颞叶痴呆检测中达到最新技术水平，并提供与已知疾病模式一致的原型。

Conclusion: X-SiT不仅性能优越，还能提供可解释的预测，有助于临床决策和疾病研究。

Abstract: Interpretable models are crucial for supporting clinical decision-making,
driving advances in their development and application for medical images.
However, the nature of 3D volumetric data makes it inherently challenging to
visualize and interpret intricate and complex structures like the cerebral
cortex. Cortical surface renderings, on the other hand, provide a more
accessible and understandable 3D representation of brain anatomy, facilitating
visualization and interactive exploration. Motivated by this advantage and the
widespread use of surface data for studying neurological disorders, we present
the eXplainable Surface Vision Transformer (X-SiT). This is the first
inherently interpretable neural network that offers human-understandable
predictions based on interpretable cortical features. As part of X-SiT, we
introduce a prototypical surface patch decoder for classifying surface patch
embeddings, incorporating case-based reasoning with spatially corresponding
cortical prototypes. The results demonstrate state-of-the-art performance in
detecting Alzheimer's disease and frontotemporal dementia while additionally
providing informative prototypes that align with known disease patterns and
reveal classification errors.

</details>


### [20] [DreamAnywhere: Object-Centric Panoramic 3D Scene Generation](https://arxiv.org/abs/2506.20367)
*Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger*

Main category: cs.GR

TL;DR: DreamAnywhere是一个模块化系统，用于快速生成和原型化3D场景，解决了现有方法在视觉保真度、场景理解和多环境适应性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D场景生成方法通常仅面向正面视角，视觉保真度低，场景理解有限，且仅适用于室内或室外环境。DreamAnywhere旨在解决这些问题。

Method: 系统从文本生成360度全景图像，分解为背景和对象，通过混合修复构建完整3D表示，并将对象掩码提升为详细3D对象。支持沉浸式导航和对象级编辑。

Result: DreamAnywhere在新视角合成一致性和图像质量上显著优于现有方法，用户研究显示其技术稳健性和实用性。

Conclusion: DreamAnywhere适用于低成本电影制作，支持快速场景布局和视觉色调迭代，模块化设计使其高度可定制。

Abstract: Recent advances in text-to-3D scene generation have demonstrated significant
potential to transform content creation across multiple industries. Although
the research community has made impressive progress in addressing the
challenges of this complex task, existing methods often generate environments
that are only front-facing, lack visual fidelity, exhibit limited scene
understanding, and are typically fine-tuned for either indoor or outdoor
settings. In this work, we address these issues and propose DreamAnywhere, a
modular system for the fast generation and prototyping of 3D scenes. Our system
synthesizes a 360{\deg} panoramic image from text, decomposes it into
background and objects, constructs a complete 3D representation through hybrid
inpainting, and lifts object masks to detailed 3D objects that are placed in
the virtual environment. DreamAnywhere supports immersive navigation and
intuitive object-level editing, making it ideal for scene exploration, visual
mock-ups, and rapid prototyping -- all with minimal manual modeling. These
features make our system particularly suitable for low-budget movie production,
enabling quick iteration on scene layout and visual tone without the overhead
of traditional 3D workflows. Our modular pipeline is highly customizable as it
allows components to be replaced independently. Compared to current
state-of-the-art text and image-based 3D scene generation approaches,
DreamAnywhere shows significant improvements in coherence in novel view
synthesis and achieves competitive image quality, demonstrating its
effectiveness across diverse and challenging scenarios. A comprehensive user
study demonstrates a clear preference for our method over existing approaches,
validating both its technical robustness and practical usefulness.

</details>


### [21] [EditP23: 3D Editing via Propagation of Image Prompts to Multi-View](https://arxiv.org/abs/2506.20652)
*Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: EditP23是一种无需掩码的3D编辑方法，通过2D图像编辑传播到多视图表示，实现3D一致性编辑。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖文本提示或显式空间掩码，EditP23通过图像对（原始视图和用户编辑后的视图）实现更直观的编辑。

Method: 利用预训练的多视图扩散模型的潜在空间，通过编辑感知流传播编辑，无需优化，保持原始对象的结构和外观。

Result: 在多种对象类别和编辑场景中表现高效，无需手动掩码即可实现高保真度。

Conclusion: EditP23提供了一种高效、直观的3D编辑方法，适用于广泛的应用场景。

Abstract: We present EditP23, a method for mask-free 3D editing that propagates 2D
image edits to multi-view representations in a 3D-consistent manner. In
contrast to traditional approaches that rely on text-based prompting or
explicit spatial masks, EditP23 enables intuitive edits by conditioning on a
pair of images: an original view and its user-edited counterpart. These image
prompts are used to guide an edit-aware flow in the latent space of a
pre-trained multi-view diffusion model, allowing the edit to be coherently
propagated across views. Our method operates in a feed-forward manner, without
optimization, and preserves the identity of the original object, in both
structure and appearance. We demonstrate its effectiveness across a range of
object categories and editing scenarios, achieving high fidelity to the source
while requiring no manual masks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [22] [CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation](https://arxiv.org/abs/2506.19952)
*Deepon Halder,Thanmay Jayakumar,Raj Dabre*

Main category: cs.CL

TL;DR: CycleDistill利用LLMs和少样本翻译生成合成平行语料，通过迭代优化提升低资源语言的机器翻译质量。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言平行语料稀缺问题，提升机器翻译质量。

Method: 通过零样本或少样本翻译生成合成平行语料，迭代优化模型。

Result: 在三种印度语言上，首轮迭代平均提升20-30 chrF点。

Conclusion: CycleDistill无需大量平行语料即可显著提升翻译质量。

Abstract: Large language models (LLMs), despite their ability to perform few-shot
machine translation (MT), often lag behind dedicated MT systems trained on
parallel corpora, which are crucial for high quality machine translation (MT).
However, parallel corpora are often scarce or non-existent for low-resource
languages. In this paper, we propose CycleDistill, a bootstrapping approach
leveraging LLMs and few-shot translation to obtain high-quality MT systems.
CycleDistill involves iteratively generating synthetic parallel corpora from
monolingual corpora via zero- or few-shot MT, which is then used to fine-tune
the model that was used for generating said data for MT. CycleDistill does not
need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments
focusing on three Indian languages, by relying solely on monolingual corpora,
it can achieve high-quality machine translation, improving upon a few-shot
baseline model by over 20-30 chrF points on average in the first iteration. We
also study the effect of leveraging softmax activations during the distillation
process and observe mild improvements in translation quality.

</details>


### [23] [Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs](https://arxiv.org/abs/2506.19967)
*Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu*

Main category: cs.CL

TL;DR: 论文提出了一种名为Inference-Scaled GraphRAG的新框架，通过推理时计算扩展提升LLM在图推理中的表现，显著改善了多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识密集型推理任务中表现不佳，传统检索增强生成（RAG）方法难以捕捉知识图谱中的关系结构。

Method: 结合顺序扩展（深度链式图遍历）和并行扩展（多数投票采样轨迹），在推理-执行循环中实现图推理。

Result: 在GRBench基准测试中，该方法显著优于传统GraphRAG和其他图遍历基线。

Conclusion: 推理时扩展是一种实用且与架构无关的解决方案，可提升LLMs在结构化知识推理中的表现。

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in
language understanding and generation, yet they continue to underperform on
knowledge-intensive reasoning tasks due to limited access to structured context
and multi-hop information. Retrieval-Augmented Generation (RAG) partially
mitigates this by grounding generation in retrieved context, but conventional
RAG and GraphRAG methods often fail to capture relational structure across
nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel
framework that enhances LLM-based graph reasoning by applying inference-time
compute scaling. Our method combines sequential scaling with deep
chain-of-thought graph traversal, and parallel scaling with majority voting
over sampled trajectories within an interleaved reasoning-execution loop.
Experiments on the GRBench benchmark demonstrate that our approach
significantly improves multi-hop question answering performance, achieving
substantial gains over both traditional GraphRAG and prior graph traversal
baselines. These findings suggest that inference-time scaling is a practical
and architecture-agnostic solution for structured knowledge reasoning with LLMs

</details>


### [24] [Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation](https://arxiv.org/abs/2506.19998)
*Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong*

Main category: cs.CL

TL;DR: Doc2Agent是一个可扩展的管道，用于从API文档生成可执行工具，并通过代码代理迭代优化，显著提升了性能和成本效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界的API复杂且多样化，现有工具集无法满足需求，需要一种方法从非结构化API文档中构建工具代理。

Method: Doc2Agent从API文档生成Python工具，并通过代码代理迭代优化这些工具。

Result: 在WebArena基准测试中，性能提升了55%，成本降低了90%，并在特定领域（如糖材料科学）展示了适应性。

Conclusion: Doc2Agent为从非结构化API文档大规模构建工具代理提供了通用解决方案。

Abstract: REST APIs play important roles in enriching the action space of web agents,
yet most API-based agents rely on curated and uniform toolsets that do not
reflect the complexity of real-world APIs. Building tool-using agents for
arbitrary domains remains a major challenge, as it requires reading
unstructured API documentation, testing APIs and inferring correct parameters.
We propose Doc2Agent, a scalable pipeline to build agents that can call
Python-based tools generated from API documentation. Doc2Agent generates
executable tools from API documentations and iteratively refines them using a
code agent. We evaluate our approach on real-world APIs, WebArena APIs, and
research APIs, producing validated tools. We achieved a 55\% relative
performance improvement with 90\% lower cost compared to direct API calling on
WebArena benchmark. A domain-specific agent built for glycomaterial science
further demonstrates the pipeline's adaptability to complex, knowledge-rich
tasks. Doc2Agent offers a generalizable solution for building tool agents from
unstructured API documentation at scale.

</details>


### [25] [A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs](https://arxiv.org/abs/2506.20073)
*Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang*

Main category: cs.CL

TL;DR: STReason是一个结合大型语言模型和时空模型的新框架，支持多任务推理和复杂长形式推理，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时空数据挖掘模型局限于单一任务，缺乏多任务推理和深入解释能力，限制了实际应用。

Method: STReason利用上下文学习将复杂查询分解为模块化程序，无需任务特定微调，生成解决方案和详细解释。

Result: 实验表明，STReason在所有指标上显著优于先进的大型语言模型基线，尤其在复杂推理场景中表现突出。

Conclusion: STReason为开发更通用和强大的时空推理系统提供了有前景的方向，并展示了实际应用潜力。

Abstract: Spatio-temporal data mining plays a pivotal role in informed decision making
across diverse domains. However, existing models are often restricted to narrow
tasks, lacking the capacity for multi-task inference and complex long-form
reasoning that require generation of in-depth, explanatory outputs. These
limitations restrict their applicability to real-world, multi-faceted decision
scenarios. In this work, we introduce STReason, a novel framework that
integrates the reasoning strengths of large language models (LLMs) with the
analytical capabilities of spatio-temporal models for multi-task inference and
execution. Without requiring task-specific finetuning, STReason leverages
in-context learning to decompose complex natural language queries into modular,
interpretable programs, which are then systematically executed to generate both
solutions and detailed rationales. To facilitate rigorous evaluation, we
construct a new benchmark dataset and propose a unified evaluation framework
with metrics specifically designed for long-form spatio-temporal reasoning.
Experimental results show that STReason significantly outperforms advanced LLM
baselines across all metrics, particularly excelling in complex,
reasoning-intensive spatio-temporal scenarios. Human evaluations further
validate STReason's credibility and practical utility, demonstrating its
potential to reduce expert workload and broaden the applicability to real-world
spatio-temporal tasks. We believe STReason provides a promising direction for
developing more capable and generalizable spatio-temporal reasoning systems.

</details>


### [26] [SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization](https://arxiv.org/abs/2506.20081)
*Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie*

Main category: cs.CL

TL;DR: 论文分析了代码检索的依赖特征，发现当前检索器过于依赖表面文本特征和文档偏见，提出了SACL框架以增强语义信息并减少偏见，显著提升了代码检索和生成的性能。


<details>
  <summary>Details</summary>
Motivation: 当前代码检索技术过于依赖表面文本特征（如文档字符串、标识符名称）和存在对文档的偏见，影响了代码生成的质量。

Method: 通过系统性地屏蔽特定特征但保留代码功能，分析代码检索的依赖特征，并提出了SACL框架，通过增强语义信息来减少偏见。

Result: SACL显著提升了代码检索性能（如HumanEval上Recall@1提升12.8%），并改善了代码生成（如HumanEval上Pass@1提升4.88%）。

Conclusion: SACL通过增强语义信息和减少偏见，显著提升了代码检索和生成的性能，为未来的代码生成技术提供了改进方向。

Abstract: Retrieval-Augmented Code Generation (RACG) is a critical technique for
enhancing code generation by retrieving relevant information. In this work, we
conduct an in-depth analysis of code retrieval by systematically masking
specific features while preserving code functionality. Our discoveries include:
(1) although trained on code, current retrievers heavily rely on surface-level
textual features (e.g., docstrings, identifier names), and (2) they exhibit a
strong bias towards well-documented code, even if the documentation is
irrelevant.Based on our discoveries, we propose SACL, a framework that enriches
textual information and reduces bias by augmenting code or structural knowledge
with semantic information. Extensive experiments show that SACL substantially
improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /
MBPP / SWE-Bench-Lite), which also leads to better code generation performance
(e.g., by 4.88% Pass@1 on HumanEval).

</details>


### [27] [Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder](https://arxiv.org/abs/2506.20083)
*Yingji Zhang,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 该论文探讨如何通过结合组合和符号语义特性提升Transformer自回归语言模型的可解释性、可控性和泛化能力，提出语义表示学习方向，并比较三种自编码器架构的潜在几何特性。


<details>
  <summary>Details</summary>
Motivation: 通过整合组合和符号语义特性，弥补分布语义与符号语义之间的差距，提升语言模型的性能。

Method: 综述并比较了三种自编码器架构（VAE、VQVAE、SAE）及其在语义结构和可解释性上的潜在几何特性。

Result: 语义表示学习方向为连接符号与分布语义提供了桥梁，不同自编码器架构在语义表示上各有特点。

Conclusion: 结合组合和符号语义特性是提升语言模型性能的有效途径，未来可进一步探索语义表示学习的应用。

Abstract: Integrating compositional and symbolic properties into current distributional
semantic spaces can enhance the interpretability, controllability,
compositionality, and generalisation capabilities of Transformer-based
auto-regressive language models (LMs). In this survey, we offer a novel
perspective on latent space geometry through the lens of compositional
semantics, a direction we refer to as \textit{semantic representation
learning}. This direction enables a bridge between symbolic and distributional
semantics, helping to mitigate the gap between them. We review and compare
three mainstream autoencoder architectures-Variational AutoEncoder (VAE),
Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the
distinctive latent geometries they induce in relation to semantic structure and
interpretability.

</details>


### [28] [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)
*Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei*

Main category: cs.CL

TL;DR: 论文提出了Time-Series QA任务和EngineMT-QA数据集，并设计了Instruct Time Transformer (ITFormer)框架，用于高效融合时间序列与自然语言，显著提升问答准确性。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在多个领域至关重要，但如何将其与自然语言高效结合以支持动态交互任务仍具挑战性。

Method: 提出ITFormer框架，结合时间序列编码器与冻结的大型语言模型，提取、对齐并融合时序与文本特征。

Result: ITFormer在问答准确性上显著优于基线模型，且仅增加不到1%的可训练参数。

Conclusion: 研究为多模态AI中时序数据与自然语言的结合提供了高效范式，推动了相关研究和应用。

Abstract: Time-series data are critical in diverse applications, such as industrial
monitoring, medical diagnostics, and climate research. However, effectively
integrating these high-dimensional temporal signals with natural language for
dynamic, interactive tasks remains a significant challenge. To address this, we
introduce the Time-Series Question Answering (Time-Series QA) task and release
EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset
designed to capture complex interactions between time-series signals and
natural language. Building on this resource, we propose the Instruct Time
Transformer (ITFormer), a novel framework that bridges time-series encoders
with frozen large language models (LLMs). ITFormer effectively extracts,
aligns, and fuses temporal and textual features, achieving a strong improvement
in QA accuracy over strong baselines with fewer than 1\% additional trainable
parameters. By combining computational efficiency with robust cross-modal
modeling, our work establishes a adaptable paradigm for integrating temporal
data with natural language, paving the way for new research and applications in
multi-modal AI. More details about the project, including datasets and code,
are available at: https://pandalin98.github.io/itformer_site/

</details>


### [29] [A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection](https://arxiv.org/abs/2506.20112)
*Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon*

Main category: cs.CL

TL;DR: 三阶段LLM框架显著提高放射学报告的正预测值（PPV）并降低运营成本。


<details>
  <summary>Details</summary>
Motivation: 由于错误率低，基于LLM的放射学报告校对的正预测值有限，需改进框架以提高效率和准确性。

Method: 通过三阶段LLM框架（检测器、提取器加检测器、提取器加检测器加假阳性验证器）分析1,000份放射学报告，并验证于外部数据集。

Result: 三阶段框架PPV显著提升至0.159，运营成本降低42.6%，检测性能稳定。

Conclusion: 三阶段LLM框架为AI辅助放射学报告质量保证提供了高效策略。

Abstract: Background: The positive predictive value (PPV) of large language model
(LLM)-based proofreading for radiology reports is limited due to the low error
prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV
and reduces operational costs compared with baseline approaches. Materials and
Methods: A retrospective analysis was performed on 1,000 consecutive radiology
reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III
database. Two external datasets (CheXpert and Open-i) were validation sets.
Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor
plus detector; and (3) extractor, detector, and false-positive verifier.
Precision was measured by PPV and absolute true positive rate (aTPR).
Efficiency was calculated from model inference charges and reviewer
remuneration. Statistical significance was tested using cluster bootstrap,
exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV
increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,
Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.
baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per
1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and
USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.
Human-reviewed reports decreased from 192 to 88. External validation supported
Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR
(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and
reduced operational costs, maintaining detection performance, providing an
effective strategy for AI-assisted radiology report quality assurance.

</details>


### [30] [Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests](https://arxiv.org/abs/2506.20119)
*Masaki Uto,Yuma Ito*

Main category: cs.CL

TL;DR: 提出一种利用自动评分技术填补缺失分数的新方法，以提高IRT能力估计的准确性，同时显著减少人工评分工作量。


<details>
  <summary>Details</summary>
Motivation: 评估学习者的高阶能力（如表达能力和逻辑思维）需求增加，但传统构建反应测试需要大量人工评分，成本高且耗时。IRT虽能从不完整分数数据估计能力，但缺失分数比例增加时准确性下降。

Method: 利用自动评分技术填补缺失分数，结合IRT进行能力估计。

Result: 新方法在能力估计中实现高准确性，并显著减少人工评分工作量。

Conclusion: 该方法为解决IRT在稀疏或异构数据中的局限性提供了有效方案，同时优化了评分效率。

Abstract: Evaluating the abilities of learners is a fundamental objective in the field
of education. In particular, there is an increasing need to assess higher-order
abilities such as expressive skills and logical thinking. Constructed-response
tests such as short-answer and essay-based questions have become widely used as
a method to meet this demand. Although these tests are effective, they require
substantial manual grading, making them both labor-intensive and costly. Item
response theory (IRT) provides a promising solution by enabling the estimation
of ability from incomplete score data, where human raters grade only a subset
of answers provided by learners across multiple test items. However, the
accuracy of ability estimation declines as the proportion of missing scores
increases. Although data augmentation techniques for imputing missing scores
have been explored in order to address this limitation, they often struggle
with inaccuracy for sparse or heterogeneous data. To overcome these challenges,
this study proposes a novel method for imputing missing scores by leveraging
automated scoring technologies for accurate IRT-based ability estimation. The
proposed method achieves high accuracy in ability estimation while markedly
reducing manual grading workload.

</details>


### [31] [CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation](https://arxiv.org/abs/2506.20128)
*Aashiq Muhamed*

Main category: cs.CL

TL;DR: 论文提出了一种名为CCRS的新评估框架，用于评估RAG系统的多维度质量，包括上下文连贯性、问题相关性等，并通过实验验证其有效性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法全面捕捉RAG输出的多维质量（如事实准确性、信息完整性等），且效率低下。

Method: 提出CCRS，基于预训练LLM的零样本端到端评估框架，包含五个指标：上下文连贯性、问题相关性等。

Result: 在BioASQ数据集上验证，CCRS能有效区分不同RAG系统性能，且比RAGChecker更高效。

Conclusion: CCRS为RAG系统提供了一种实用、全面且高效的评估框架。

Abstract: RAG systems enhance LLMs by incorporating external knowledge, which is
crucial for domains that demand factual accuracy and up-to-date information.
However, evaluating the multifaceted quality of RAG outputs, spanning aspects
such as contextual coherence, query relevance, factual correctness, and
informational completeness, poses significant challenges. Existing evaluation
methods often rely on simple lexical overlap metrics, which are inadequate for
capturing these nuances, or involve complex multi-stage pipelines with
intermediate steps like claim extraction or require finetuning specialized
judge models, hindering practical efficiency. To address these limitations, we
propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five
metrics that utilizes a single, powerful, pretrained LLM as a zero-shot,
end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance
(QR), Information Density (ID), Answer Correctness (AC), and Information Recall
(IR). We apply CCRS to evaluate six diverse RAG system configurations on the
challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively
discriminates between system performances, confirming, for instance, that the
Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of
CCRS metric properties, including score distributions, convergent/discriminant
validity, tie rates, population statistics, and discriminative power. Compared
to the complex RAGChecker framework, CCRS offers comparable or superior
discriminative power for key aspects like recall and faithfulness, while being
significantly more computationally efficient. CCRS thus provides a practical,
comprehensive, and efficient framework for evaluating and iteratively improving
RAG systems.

</details>


### [32] [AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control](https://arxiv.org/abs/2506.20160)
*Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du*

Main category: cs.CL

TL;DR: AALC是一种轻量级的准确性感知长度奖励方法，通过动态平衡正确性和简洁性，显著减少推理模型的响应长度，同时保持或提升准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）通过生成冗长的思维链获得强大的推理能力，但这种方式带来了高延迟和成本，而准确性提升有限。

Method: AALC将验证准确性纳入奖励机制，并采用动态调度的长度惩罚，延迟长度惩罚直至达到目标性能。

Result: 实验表明，AALC将响应长度减少50%以上，同时保持或提升准确性，并减少冗余推理模式。

Conclusion: AALC展示了基于奖励的策略在引导LRMs实现更高效、通用推理路径方面的潜力，但也可能降低模型的解释性。

Abstract: Large reasoning models (LRMs) achieve impressive reasoning capabilities by
generating lengthy chain-of-thoughts, but this "overthinking" incurs high
latency and cost without commensurate accuracy gains. In this work, we
introduce AALC, a lightweight, accuracy-aware length reward integrated into
reinforcement learning that dynamically balances correctness and brevity during
training. By incorporating validation accuracy into the reward and employing a
smooth, dynamically scheduled length penalty, AALC delays length penalty until
target performance is met. Through extensive experiments across standard and
out-of-distribution math benchmarks, we show that our approach reduces response
length by over 50% while maintaining or even improving the original accuracy.
Furthermore, qualitative analysis reveals that our method curbs redundant
reasoning patterns such as excessive subgoal setting and verification, leading
to structurally refined outputs rather than naive truncation. We also identify
that efficiency gains are accompanied by reduced interpretability: models
trained with AALC omit some narrative framing and explanatory context. These
findings highlight the potential of reward-based strategies to guide LRMs
toward more efficient, generalizable reasoning paths.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [Prover Agent: An Agent-based Framework for Formal Mathematical Proofs](https://arxiv.org/abs/2506.19923)
*Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai*

Main category: cs.AI

TL;DR: Prover Agent是一种新型AI代理，结合大型语言模型（LLMs）和形式化证明助手Lean，实现自动定理证明，成功率达86.1%。


<details>
  <summary>Details</summary>
Motivation: 解决自动定理证明中LLMs与形式化工具的协同问题，提高证明效率和成功率。

Method: 整合非正式推理LLM、形式化证明模型和Lean反馈，生成辅助引理以发现整体证明策略。

Result: 在MiniF2F基准测试中达到86.1%的成功率，优于其他小语言模型方法。

Conclusion: Prover Agent通过协同LLMs和Lean，显著提升了自动定理证明的性能。

Abstract: We present Prover Agent, a novel AI agent for automated theorem proving that
integrates large language models (LLMs) with a formal proof assistant, Lean.
Prover Agent coordinates an informal reasoning LLM, a formal prover model, and
feedback from Lean while also generating auxiliary lemmas to assist in
discovering the overall proof strategy. It achieves an 86.1% success rate on
the MiniF2F benchmark, establishing a new state-of-the-art among methods using
small language models (SLMs) with a much lower sample budget than previous
approaches. We also present case studies illustrating how these generated
lemmas contribute to solving challenging problems.

</details>


### [34] [Context Attribution with Multi-Armed Bandit Optimization](https://arxiv.org/abs/2506.19977)
*Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla*

Main category: cs.AI

TL;DR: 提出了一种基于组合多臂老虎机（CMAB）的框架，用于高效识别检索上下文中对生成答案贡献最大的部分，提升生成式QA系统的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 理解检索上下文中哪些部分对生成答案有贡献，对构建可解释且可信的生成式QA系统至关重要。

Method: 将上下文归因问题建模为组合多臂老虎机问题，使用组合汤普森采样（CTS）在有限查询预算下高效探索上下文子集空间，定义基于归一化标记似然的奖励函数。

Result: 在多种数据集和LLM上的实验表明，该方法能以更少的模型查询实现竞争性的归因质量。

Conclusion: 提出的方法显著提高了查询效率，同时保持了高归因保真度，优于传统的扰动归因方法。

Abstract: Understanding which parts of the retrieved context contribute to a large
language model's generated answer is essential for building interpretable and
trustworthy generative QA systems. We propose a novel framework that formulates
context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each
context segment is treated as a bandit arm, and we employ Combinatorial
Thompson Sampling (CTS) to efficiently explore the exponentially large space of
context subsets under a limited query budget. Our method defines a reward
function based on normalized token likelihoods, capturing how well a subset of
segments supports the original model response. Unlike traditional
perturbation-based attribution methods such as SHAP, which sample subsets
uniformly and incur high computational costs, our approach adaptively balances
exploration and exploitation by leveraging posterior estimates of segment
relevance. This leads to substantially improved query efficiency while
maintaining high attribution fidelity. Extensive experiments on diverse
datasets and LLMs demonstrate that our method achieves competitive attribution
quality with fewer model queries.

</details>


### [35] [QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](https://arxiv.org/abs/2506.20008)
*Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique*

Main category: cs.AI

TL;DR: 论文评估了大型语言模型（LLMs）在PennyLane量子代码生成中的表现，引入QHackBench基准数据集，并比较了标准提示与检索增强生成（RAG）的效果。结果表明RAG在复杂量子算法中表现接近标准提示，同时提出了多代理评估管道以提升成功率。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在量子计算代码生成中的潜力，填补现有研究的空白。

Method: 使用QHackBench数据集，评估LLMs在标准提示和RAG下的表现，并引入多代理评估管道优化结果。

Result: RAG在复杂任务中表现接近标准提示，多代理管道显著提升了执行成功率。

Conclusion: 论文为AI辅助量子编程提供了新工具和基准，推动了该领域的研究。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated strong
potential in code generation, yet their effectiveness in quantum computing
remains underexplored. This paper benchmarks LLMs for PennyLane-based quantum
code generation using real-world challenges from the Quantum Hackathon (QHack).
We introduce QHackBench, a novel benchmark dataset derived from QHack
competitions, and evaluate model performance under vanilla prompting and
Retrieval-Augmented Generation (RAG). Our structured evaluation framework
assesses functional correctness, syntactic validity, and execution success
across varying challenge difficulties. Results indicate that RAG-enhanced
models, supplemented with an augmented PennyLane dataset, approximately
generate similar results as the standard prompting, particularly in complex
quantum algorithms. Additionally, we introduce a multi-agent evaluation
pipeline that iteratively refines incorrect solutions, further enhancing
execution success rates. To foster further research, we commit to publicly
releasing QHackBench, along with our evaluation framework and experimental
results, enabling continued advancements in AI-assisted quantum programming.

</details>


### [36] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
*Konstantinos Vrettos,Michail E. Klontzas*

Main category: cs.AI

TL;DR: 研究开发了一种可定制的RAG框架，用于医疗任务，其性能优于商业LLM，同时能耗更低。


<details>
  <summary>Details</summary>
Motivation: 解决AI在医疗领域的环境和伦理问题，如资源消耗和患者隐私。

Method: 开发了监控能耗和CO2排放的RAG框架，并基于开源LLM构建RAG模型进行测试。

Result: 自定义RAG模型在准确性和能耗上均优于商业模型，llama3.1:8B表现最佳。

Conclusion: 本地LLM开发的RAG在医疗任务中优于商业LLM，且更环保，符合可持续发展目标。

Abstract: Background The increasing adoption of Artificial Intelligence (AI) in
healthcare has sparked growing concerns about its environmental and ethical
implications. Commercial Large Language Models (LLMs), such as ChatGPT and
DeepSeek, require substantial resources, while the utilization of these systems
for medical purposes raises critical issues regarding patient privacy and
safety. Methods We developed a customizable Retrieval-Augmented Generation
(RAG) framework for medical tasks, which monitors its energy usage and CO2
emissions. This system was then used to create RAGs based on various
open-source LLMs. The tested models included both general purpose models like
llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs
performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs
o4-mini model. A dataset of medical questions was used for the evaluation.
Results Custom RAG models outperformed commercial models in accuracy and energy
consumption. The RAG model built on llama3.1:8B achieved the highest accuracy
(58.5%) and was significantly better than other models, including o4-mini and
DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption
and CO2 footprint among all models, with a Performance per kWh of 0.52 and a
total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x
times more accuracy points per kWh and 172% less electricity usage while
maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs
can be leveraged to develop RAGs that outperform commercial, online LLMs in
medical tasks, while having a smaller environmental impact. Our modular
framework promotes sustainable AI development, reducing electricity usage and
aligning with the UNs Sustainable Development Goals.

</details>


### [37] [Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](https://arxiv.org/abs/2506.20018)
*Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao*

Main category: cs.AI

TL;DR: 论文探讨了实时决策支持系统，结合低延迟AI模型、Edge-IoT技术和人机协作方法，研究如何利用大语言模型辅助资源受限的决策。


<details>
  <summary>Details</summary>
Motivation: 研究旨在整合AI驱动的决策工具与边缘计算技术，解决资源受限和适应性框架需求的问题。

Method: 通过详细综述，分析DeLLMa等技术进展、模型压缩方法和边缘设备分析改进。

Result: 提供了开发策略和应用领域的实用视角，指出高效灵活AI系统的机会。

Conclusion: 为未来实时决策支持领域的突破奠定基础，强调AI重塑决策的潜力。

Abstract: This paper investigates real-time decision support systems that leverage
low-latency AI models, bringing together recent progress in holistic AI-driven
decision tools, integration with Edge-IoT technologies, and approaches for
effective human-AI teamwork. It looks into how large language models can assist
decision-making, especially when resources are limited. The research also
examines the effects of technical developments such as DeLLMa, methods for
compressing models, and improvements for analytics on edge devices, while also
addressing issues like limited resources and the need for adaptable frameworks.
Through a detailed review, the paper offers practical perspectives on
development strategies and areas of application, adding to the field by
pointing out opportunities for more efficient and flexible AI-supported
systems. The conclusions set the stage for future breakthroughs in this
fast-changing area, highlighting how AI can reshape real-time decision support.

</details>


### [38] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型（LLMs）在分配特定身份角色后，会表现出类似人类的动机性推理，且难以通过常规方法消除偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否会在身份角色分配后表现出动机性推理，以及这种偏见对社会的潜在影响。

Method: 为8个LLMs分配8种不同政治和社会人口属性角色，测试其在信息真实性辨别和科学证据评估任务中的表现。

Result: 身份角色分配的LLMs在信息辨别能力上降低9%，政治角色在科学证据评估中表现出90%的偏见倾向。去偏见方法效果有限。

Conclusion: LLMs表现出类似人类的动机性推理，且难以消除，可能加剧社会中的身份偏见问题。

Abstract: Reasoning in humans is prone to biases due to underlying motivations like
identity protection, that undermine rational decision-making and judgment. This
motivated reasoning at a collective level can be detrimental to society when
debating critical issues such as human-driven climate change or vaccine safety,
and can further aggravate political polarization. Prior studies have reported
that large language models (LLMs) are also susceptible to human-like cognitive
biases, however, the extent to which LLMs selectively reason toward
identity-congruent conclusions remains largely unexplored. Here, we investigate
whether assigning 8 personas across 4 political and socio-demographic
attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and
proprietary) across two reasoning tasks from human-subject studies -- veracity
discernment of misinformation headlines and evaluation of numeric scientific
evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity
discernment relative to models without personas. Political personas
specifically, are up to 90% more likely to correctly evaluate scientific
evidence on gun control when the ground truth is congruent with their induced
political identity. Prompt-based debiasing methods are largely ineffective at
mitigating these effects. Taken together, our empirical findings are the first
to suggest that persona-assigned LLMs exhibit human-like motivated reasoning
that is hard to mitigate through conventional debiasing prompts -- raising
concerns of exacerbating identity-congruent reasoning in both LLMs and humans.

</details>


### [39] [DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction](https://arxiv.org/abs/2506.20059)
*Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar*

Main category: cs.AI

TL;DR: DiaLLM是一种新型医疗LLM，整合了电子健康记录（EHR）数据，支持临床测试推荐、结果解释和诊断预测，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有医疗LLM忽视EHR的作用且仅关注诊断推荐，限制了临床实用性。DiaLLM旨在通过整合EHR数据提升临床实践中的实用性。

Method: 提出Clinical Test Reference（CTR）策略，将临床代码映射为描述并分类测试结果；采用强化学习框架，引入拒绝采样策略以减少冗余，并设计确认奖励和类别敏感诊断奖励。

Result: 实验表明DiaLLM在临床测试推荐和诊断预测上优于基线方法。

Conclusion: DiaLLM通过整合EHR数据和优化策略，显著提升了医疗LLM的临床实用性。

Abstract: Recent advances in Large Language Models (LLMs) have led to remarkable
progresses in medical consultation. However, existing medical LLMs overlook the
essential role of Electronic Health Records (EHR) and focus primarily on
diagnosis recommendation, limiting their clinical applicability. We propose
DiaLLM, the first medical LLM that integrates heterogeneous EHR data into
clinically grounded dialogues, enabling clinical test recommendation, result
interpretation, and diagnosis prediction to better align with real-world
medical practice. To construct clinically grounded dialogues from EHR, we
design a Clinical Test Reference (CTR) strategy that maps each clinical code to
its corresponding description and classifies test results as "normal" or
"abnormal". Additionally, DiaLLM employs a reinforcement learning framework for
evidence acquisition and automated diagnosis. To handle the large action space,
we introduce a reject sampling strategy to reduce redundancy and improve
exploration efficiency. Furthermore, a confirmation reward and a
class-sensitive diagnosis reward are designed to guide accurate diagnosis
prediction. Extensive experimental results demonstrate that DiaLLM outperforms
baselines in clinical test recommendation and diagnosis prediction.

</details>


### [40] [AI Copilots for Reproducibility in Science: A Case Study](https://arxiv.org/abs/2506.20130)
*Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil*

Main category: cs.AI

TL;DR: OpenPub是一个AI驱动的平台，通过模块化助手支持开放科学任务，特别是可复现性。其Reproducibility Copilot能分析论文、代码和补充材料，生成结构化Jupyter Notebook和建议，显著减少复现时间。


<details>
  <summary>Details</summary>
Motivation: 开放科学倡议旨在提高研究输出的透明度和可复用性，但独立复现研究成果仍具挑战性。

Method: OpenPub平台通过Reproducibility Copilot分析研究材料，生成结构化Notebook和建议，并进行可行性测试。

Result: 测试显示，OpenPub能将复现时间从30多小时缩短至约1小时，并高覆盖率地复现图表和结果。

Conclusion: AI工具可显著减轻复现负担，促进更透明的科学交流，模块化架构还可扩展至其他开放科学目标。

Abstract: Open science initiatives seek to make research outputs more transparent,
accessible, and reusable, but ensuring that published findings can be
independently reproduced remains a persistent challenge. This paper introduces
OpenPub, an AI-powered platform that supports researchers, reviewers, and
readers through a suite of modular copilots focused on key open science tasks.
In this work, we present the Reproducibility Copilot, which analyzes
manuscripts, code, and supplementary materials to generate structured Jupyter
Notebooks and recommendations aimed at facilitating computational, or "rote",
reproducibility. We conducted feasibility tests using previously studied
research papers with known reproducibility benchmarks. Results indicate that
OpenPub can substantially reduce reproduction time - from over 30 hours to
about 1 hour - while achieving high coverage of figures, tables, and results
suitable for computational reproduction. The system systematically detects
barriers to reproducibility, including missing hyperparameters, undocumented
preprocessing steps, and incomplete or inaccessible datasets. These findings
suggest that AI-driven tools can meaningfully reduce the burden of
reproducibility efforts and contribute to more transparent and verifiable
scientific communication. The modular copilot architecture also provides a
foundation for extending AI assistance to additional open science objectives
beyond reproducibility.

</details>


### [41] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
*Junyan Cheng,Peter Clark,Kyle Richardson*

Main category: cs.AI

TL;DR: 利用多智能体LLM模拟研究过程，提出Genesys系统，通过遗传编程生成新架构设计，在多个规模上验证，性能优于已知架构。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以利用LLM模拟发现新语言模型架构的过程，提高研究效率。

Method: 采用多智能体LLM方法，结合遗传编程和Ladder of Scales策略，分阶段生成、验证设计。

Result: 生成1,162个新设计，其中1,062个通过预训练验证，性能优于GPT2和Mamba2等架构。

Conclusion: Genesys系统在自主发现新架构方面高效且性能优越，为自动化研究系统设计提供了新思路。

Abstract: Can we leverage LLMs to model the process of discovering novel language model
(LM) architectures? Inspired by real research, we propose a multi-agent LLM
approach that simulates the conventional stages of research, from ideation and
literature search (proposal stage) to design implementation (code generation),
generative pre-training, and downstream evaluation (verification). Using ideas
from scaling laws, our system, Genesys, employs a Ladder of Scales approach;
new designs are proposed, adversarially reviewed, implemented, and selectively
verified at increasingly larger model scales (14M$\sim$350M parameters) with a
narrowing budget (the number of models we can train at each scale). To help
make discovery efficient and factorizable, Genesys uses a novel genetic
programming backbone, which we show has empirical advantages over commonly used
direct prompt generation workflows (e.g., $\sim$86\% percentage point
improvement in successful design generation, a key bottleneck). We report
experiments involving 1,162 newly discovered designs (1,062 fully verified
through pre-training) and find the best designs to be highly competitive with
known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common
benchmarks). We couple these results with comprehensive system-level ablations
and formal results, which give broader insights into the design of effective
autonomous discovery systems.

</details>


### [42] [Enterprise Large Language Model Evaluation Benchmark](https://arxiv.org/abs/2506.20274)
*Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li*

Main category: cs.AI

TL;DR: 提出一个基于Bloom分类法的14任务框架，用于全面评估大语言模型在企业环境中的能力，并开发了一个可扩展的标注与评估流程。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如MMLU）未能充分评估企业特定任务的复杂性，需要更全面的评估方法。

Method: 结合LLM-as-a-Labeler、LLM-as-a-Judge和CRAG技术，构建了9,700样本的基准数据集。

Result: 开源模型在推理任务中表现接近专有模型，但在判断任务中表现较差，可能因过度思考。

Conclusion: 该工作为企业提供了定制化评估的蓝图，并推动了LLM的实际部署。

Abstract: Large Language Models (LLMs) ) have demonstrated promise in boosting
productivity across AI-powered tools, yet existing benchmarks like Massive
Multitask Language Understanding (MMLU) inadequately assess enterprise-specific
task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy
to holistically evaluate LLM capabilities in enterprise contexts. To address
challenges of noisy data and costly annotation, we develop a scalable pipeline
combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented
generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six
leading models shows open-source contenders like DeepSeek R1 rival proprietary
models in reasoning tasks but lag in judgment-based scenarios, likely due to
overthinking. Our benchmark reveals critical enterprise performance gaps and
offers actionable insights for model optimization. This work provides
enterprises a blueprint for tailored evaluations and advances practical LLM
deployment.

</details>


### [43] [Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards](https://arxiv.org/abs/2506.20332)
*Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 论文提出Mobile-R1方法，通过多轮交互式强化学习与任务级奖励提升移动代理的探索与纠错能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于离线强化学习或动作级奖励的在线优化，导致代理易陷入局部最优，探索与纠错能力不足。

Method: 采用三阶段训练框架：初始格式微调、动作级奖励单步在线训练、任务级奖励多轮轨迹在线训练。

Result: 显著提升代理性能，并构建包含28个中文应用的数据集与500轨迹的基准测试。

Conclusion: Mobile-R1通过任务级奖励和多轮训练有效增强代理能力，相关资源将开源。

Abstract: Vision-language model-based mobile agents have gained the ability to not only
understand complex instructions and mobile screenshots, but also optimize their
action outputs via thinking and reasoning, benefiting from reinforcement
learning, such as Group Relative Policy Optimization (GRPO). However, existing
research centers on offline reinforcement learning training or online
optimization using action-level rewards, which limits the agent's dynamic
interaction with the environment. This often results in agents settling into
local optima, thereby weakening their ability for exploration and error action
correction. To address these challenges, we introduce an approach called
Mobile-R1, which employs interactive multi-turn reinforcement learning with
task-level rewards for mobile agents. Our training framework consists of three
stages: initial format finetuning, single-step online training via action-level
reward, followed by online training via task-level reward based on multi-turn
trajectories. This strategy is designed to enhance the exploration and error
correction capabilities of Mobile-R1, leading to significant performance
improvements. Moreover, we have collected a dataset covering 28 Chinese
applications with 24,521 high-quality manual annotations and established a new
benchmark with 500 trajectories. We will open source all resources, including
the dataset, benchmark, model weight, and codes:
https://mobile-r1.github.io/Mobile-R1/.

</details>


### [44] [Tabular Feature Discovery With Reasoning Type Exploration](https://arxiv.org/abs/2506.20357)
*Sungwon Han,Sungkyu Park,Seungeon Lee*

Main category: cs.AI

TL;DR: 论文提出了一种名为REFeat的新方法，通过多类型推理引导大型语言模型（LLM）生成多样且信息丰富的特征，解决了现有LLM方法生成特征过于简单或重复的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的特征生成方法存在生成特征过于简单或重复的问题，部分原因是LLM的固有偏见和缺乏结构化推理指导。

Method: 提出REFeat方法，利用多类型推理引导LLM生成特征，实验在59个基准数据集上进行。

Result: 实验表明，REFeat不仅平均预测准确率更高，还能生成更多样且有意义的特征。

Conclusion: 研究展示了在LLM驱动的表格数据特征发现中结合丰富推理范式和自适应策略选择的潜力。

Abstract: Feature engineering for tabular data remains a critical yet challenging step
in machine learning. Recently, large language models (LLMs) have been used to
automatically generate new features by leveraging their vast knowledge.
However, existing LLM-based approaches often produce overly simple or
repetitive features, partly due to inherent biases in the transformations the
LLM chooses and the lack of structured reasoning guidance during generation. In
this paper, we propose a novel method REFeat, which guides an LLM to discover
diverse and informative features by leveraging multiple types of reasoning to
steer the feature generation process. Experiments on 59 benchmark datasets
demonstrate that our approach not only achieves higher predictive accuracy on
average, but also discovers more diverse and meaningful features. These results
highlight the promise of incorporating rich reasoning paradigms and adaptive
strategy selection into LLM-driven feature discovery for tabular data.

</details>


### [45] [Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios](https://arxiv.org/abs/2506.20384)
*Dror Ivry,Oran Nahum*

Main category: cs.AI

TL;DR: 论文提出了Paladin-mini模型和grounding-benchmark数据集，用于解决上下文中的声明验证问题，并展示了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决在给定上下文中验证声明是否有支持证据的问题。

Method: 提出Paladin-mini（3.8B参数的开源分类模型）和grounding-benchmark评估数据集。

Result: 展示了Paladin-mini与当前最先进技术的对比结果，性能稳健且可复现。

Conclusion: Paladin-mini和grounding-benchmark为声明验证任务提供了有效的解决方案。

Abstract: This paper introduces two significant contributions to address the issue of
grounding claims in a given context. Grounding means that given a context
(document) and a claim, there's at least one supportive evidence for the claim
in the document. We will introduce Paladin-mini, a compact (3.8B parameters)
open-source classifier model (used for labeling data as grounded or ungrounded)
engineered for robust performance in real-world scenarios, and the
grounding-benchmark, a new evaluation dataset designed to assess performance on
critical reasoning tasks. We'll also demonstrate the results of Paladin-mini
with benchmarks against the current State-of-the-art and share clear and
reproducible results.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [46] [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://arxiv.org/abs/2506.19999)
*Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell*

Main category: cs.LG

TL;DR: 论文提出了一种基于时空点过程的概率模型，用于更全面地模拟阅读行为，包括注视点的位置、时间和持续时间，以及眼跳的动态特性。


<details>
  <summary>Details</summary>
Motivation: 现有模型通常依赖于聚合的眼动追踪数据和强假设，忽略了阅读过程中的时空动态特性，因此需要更通用的模型来捕捉这些细节。

Method: 使用标记的时空点过程模型，其中眼跳通过Hawkes过程建模，注视持续时间通过时间卷积的预测因子建模。

Result: Hawkes过程模型比基线模型更好地拟合了人类的眼跳行为，但上下文意外性对注视持续时间的预测准确性提升有限。

Conclusion: 研究结果表明，意外性理论在解释精细眼动行为方面存在局限性，而提出的模型为阅读行为提供了更全面的描述。

Abstract: Reading is a process that unfolds across space and time, alternating between
fixations where a reader focuses on a specific point in space, and saccades
where a reader rapidly shifts their focus to a new point. An ansatz of
psycholinguistics is that modeling a reader's fixations and saccades yields
insight into their online sentence processing. However, standard approaches to
such modeling rely on aggregated eye-tracking measurements and models that
impose strong assumptions, ignoring much of the spatio-temporal dynamics that
occur during reading. In this paper, we propose a more general probabilistic
model of reading behavior, based on a marked spatio-temporal point process,
that captures not only how long fixations last, but also where they land in
space and when they take place in time. The saccades are modeled using a Hawkes
process, which captures how each fixation excites the probability of a new
fixation occurring near it in time and space. The duration time of fixation
events is modeled as a function of fixation-specific predictors convolved
across time, thus capturing spillover effects. Empirically, our Hawkes process
model exhibits a better fit to human saccades than baselines. With respect to
fixation durations, we observe that incorporating contextual surprisal as a
predictor results in only a marginal improvement in the model's predictive
accuracy. This finding suggests that surprisal theory struggles to explain
fine-grained eye movements.

</details>


### [47] [MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations](https://arxiv.org/abs/2506.20100)
*Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve*

Main category: cs.LG

TL;DR: MIRAGE是一个新的多模态基准测试，专注于农业领域的专家级推理和决策，结合自然用户查询、专家回答和图像上下文，用于评估模型在真实世界知识密集型任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常依赖明确输入和封闭分类，而MIRAGE旨在捕捉真实咨询场景的复杂性，包括未明确输入和开放世界设置，以推动模型在推理和生成方面的进步。

Method: 基于35,000多个真实用户-专家交互数据，通过多步骤流程构建，涵盖作物健康、害虫诊断和管理场景，包含7,000多个生物实体。

Result: MIRAGE成为视觉语言模型中分类最多样化的基准之一，支持开放世界场景下的推理和生成任务。

Conclusion: MIRAGE为多模态模型在真实世界知识密集型任务中的评估提供了高保真基准，填补了现有基准的不足。

Abstract: We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning
and decision-making in consultative interaction settings. Designed for the
agriculture domain, MIRAGE captures the full complexity of expert consultations
by combining natural user queries, expert-authored responses, and image-based
context, offering a high-fidelity benchmark for evaluating models on grounded
reasoning, clarification strategies, and long-form generation in a real-world,
knowledge-intensive domain. Grounded in over 35,000 real user-expert
interactions and curated through a carefully designed multi-step pipeline,
MIRAGE spans diverse crop health, pest diagnosis, and crop management
scenarios. The benchmark includes more than 7,000 unique biological entities,
covering plant species, pests, and diseases, making it one of the most
taxonomically diverse benchmarks available for vision-language models, grounded
in the real world. Unlike existing benchmarks that rely on well-specified user
inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich
scenarios with open-world settings, requiring models to infer latent knowledge
gaps, handle rare entities, and either proactively guide the interaction or
respond. Project Page: https://mirage-benchmark.github.io

</details>
